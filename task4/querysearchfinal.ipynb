{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8461023,"sourceType":"datasetVersion","datasetId":5043667}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T15:18:23.108302Z","iopub.execute_input":"2024-05-23T15:18:23.108667Z","iopub.status.idle":"2024-05-23T15:18:23.460328Z","shell.execute_reply.started":"2024-05-23T15:18:23.108636Z","shell.execute_reply":"2024-05-23T15:18:23.459365Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Changing Paragraph to sentences","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\n# Download the necessary NLTK data files\nnltk.download('punkt')\n\n# Load the dataset\nfile_path = '/kaggle/input/task4-dataset/task4/paragraphs.xlsx'\ndf = pd.read_excel(file_path)\n\n# Ensure the columns are named appropriately\nparagraph_headings = df.iloc[:, 0]  # Assuming the headings are in the first column\nparagraphs = df.iloc[:, 2]  # Adjust the index if the paragraphs are in another column\n\n# Initialize a list to store the sentences with their corresponding paragraph heading\nsentences_with_headings = []\n\n# Process each paragraph\nfor heading, paragraph in zip(paragraph_headings, paragraphs):\n    if isinstance(paragraph, str):  # Check if the paragraph is a string\n        # Tokenize the paragraph into sentences\n        sentences = sent_tokenize(paragraph)\n        # Append the sentences and their corresponding heading to the list\n        for sentence in sentences:\n            sentences_with_headings.append((heading, sentence))\n    else:\n        # Handle non-string paragraphs (e.g., None, NaN, etc.)\n        sentences_with_headings.append((heading, paragraph))\n\n# Create a new DataFrame with the paragraph heading and sentences\nsentences_df = pd.DataFrame(sentences_with_headings, columns=['Paragraph Heading', 'Sentence'])\n\n# Save the sentences to a new Excel file\noutput_file_path = 'sentencefrompara.xlsx'\nsentences_df.to_excel(output_file_path, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:18:23.461906Z","iopub.execute_input":"2024-05-23T15:18:23.462299Z","iopub.status.idle":"2024-05-23T15:19:22.872690Z","shell.execute_reply.started":"2024-05-23T15:18:23.462271Z","shell.execute_reply":"2024-05-23T15:19:22.871890Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:19:22.874090Z","iopub.execute_input":"2024-05-23T15:19:22.874496Z","iopub.status.idle":"2024-05-23T15:19:36.328961Z","shell.execute_reply.started":"2024-05-23T15:19:22.874470Z","shell.execute_reply":"2024-05-23T15:19:36.327987Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Using a pretrained model for converting sentence to embeddings and then performing cosine similarity","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nimport torch\nfrom transformers import pipeline\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\ndef semantic_search(query,corpus_embeddings ,top_k=5):\n#     corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n    top_k = min(top_k, len(corpus))\n\n    query_embedding = embedder.encode(query, convert_to_tensor=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n    top_paragraphs = [corpus[idx] for idx in top_results[1]]\n    return top_paragraphs\n\ndef answer_question(question, top_paragraphs):\n    qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n    \n    best_answer = None\n    best_score = 0\n    best_paragraph = \"\"\n\n    for paragraph in top_paragraphs:\n        answer = qa_pipeline({'question': question, 'context': paragraph})\n        if answer['score'] > best_score:\n            best_score = answer['score']\n            best_answer = answer['answer']\n            best_paragraph = paragraph\n\n    return best_paragraph, best_answer, best_score\n\ncorpus = sentences_df['Sentence'].tolist()\ncorpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\nnp.save('corpus_embeddings.npy', corpus_embeddings.cpu().numpy())  # Save embeddings as a numpy array\ndef load_embeddings(embedding_file='corpus_embeddings.npy'):\n    return torch.tensor(np.load(embedding_file))\n\n##for loading embedding use this function and say corpus_embeddings=load_embeddings(embedding_file='corpus_embedding.npy')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:19:36.330454Z","iopub.execute_input":"2024-05-23T15:19:36.330761Z","iopub.status.idle":"2024-05-23T15:21:58.758508Z","shell.execute_reply.started":"2024-05-23T15:19:36.330732Z","shell.execute_reply":"2024-05-23T15:21:58.757337Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-23 15:19:42.451881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-23 15:19:42.451982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-23 15:19:42.587628: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57eed4a677924adaa745876cdd102166"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be68ddf839574617a705f8a51393fa70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b116c8cd4d43ef8347e568b164d4a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3048b9eacdda47e398d86468d0e3ac4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a89f02d55324f7196f140be4715d8d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7c864a17ff4295baa38434d3d52784"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f033f691ada4526a2210afab6b7389e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9716f19e77c846ea9315078f1777641c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a34a8fe6ff09456fa3d40667fac1a729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bdc17c8cd0d4c79805e7e41b5cf41b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556fc76c8c204a36aa65d02824cce3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/11996 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a991a9ff1644aa3aa1886e3b8ca4176"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Functions to get answer","metadata":{}},{"cell_type":"code","source":"def answer_question(question, bestparagraph):\n    qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n    \n    answers = []\n#     for paragraph in top_paragraphs:\n    answer = qa_pipeline({'question': question, 'context': bestparagraph})\n    answers.append((paragraph, answer['answer'], answer['score']))\n\n    # Sort answers by score in descending order\n#     answers = sorted(answers, key=lambda x: x[2], reverse=True)\n    return answers\n#  the below comment if you want to input a query\nqueries = [\n    \"What event was the first HDTV broadcast in Europe?\",\n    \"Who translated German chorales into English?\",\n    \"What entity controls the schools in Hyderabad?\"\n]\nfor query in queries:\n        if query.lower() == 'exit':\n            break\n        top_paragraphs = semantic_search(query, corpus_embeddings)\n        \n        print(\"\\nTop 5 paragraphs:\")\n        for i, para in enumerate(top_paragraphs, 1):\n            print(f\"{i}: {para}\")\n\n        question = query\n        answers = answer_question(question, top_paragraphs[0])\n        \n        print(\"\\nAnswers based on top paragraphs:\")\n        for paragraph, answer, score in answers:\n            print(f\"Answer: {answer}\\nScore: {score:.4f}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:24:27.141247Z","iopub.execute_input":"2024-05-23T15:24:27.141943Z","iopub.status.idle":"2024-05-23T15:24:31.310501Z","shell.execute_reply.started":"2024-05-23T15:24:27.141908Z","shell.execute_reply":"2024-05-23T15:24:31.309547Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b888bf3928f04ea392278b572bd2abed"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when the Italian broadcaster RAI used the HD-MAC and MUSE HDTV technologies to broadcast the 1990 FIFA World Cup.\n2: The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when the Italian broadcaster RAI used the HD-MAC and MUSE HDTV technologies to broadcast the 1990 FIFA World Cup.\n3: The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when the Italian broadcaster RAI used the HD-MAC and MUSE HDTV technologies to broadcast the 1990 FIFA World Cup.\n4: The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when the Italian broadcaster RAI used the HD-MAC and MUSE HDTV technologies to broadcast the 1990 FIFA World Cup.\n5: The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when the Italian broadcaster RAI used the HD-MAC and MUSE HDTV technologies to broadcast the 1990 FIFA World Cup.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: 1990 FIFA World Cup\nScore: 0.5656\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"328b0d3c11b446d0a0a601f75561f10e"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: A rudimentary example of translating poetry for singing is church hymns, such as the German chorales translated into English by Catherine Winkworth.\n2: A rudimentary example of translating poetry for singing is church hymns, such as the German chorales translated into English by Catherine Winkworth.\n3: A rudimentary example of translating poetry for singing is church hymns, such as the German chorales translated into English by Catherine Winkworth.\n4: A rudimentary example of translating poetry for singing is church hymns, such as the German chorales translated into English by Catherine Winkworth.\n5: A rudimentary example of translating poetry for singing is church hymns, such as the German chorales translated into English by Catherine Winkworth.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: Catherine Winkworth\nScore: 0.9717\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d27b20d5cb74f768510f3e38d3af180"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: Public and private schools in Hyderabad are governed by the Central Board of Secondary Education and follow a \"10+2+3\" plan.\n2: Public and private schools in Hyderabad are governed by the Central Board of Secondary Education and follow a \"10+2+3\" plan.\n3: Public and private schools in Hyderabad are governed by the Central Board of Secondary Education and follow a \"10+2+3\" plan.\n4: Public and private schools in Hyderabad are governed by the Central Board of Secondary Education and follow a \"10+2+3\" plan.\n5: Institutes in Hyderabad include the National Institute of Rural Development, the Indian School of Business, the Institute of Public Enterprise, the Administrative Staff College of India and the Sardar Vallabhbhai Patel National Police Academy.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: Central Board of Secondary Education\nScore: 0.6207\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# For interactive search","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    while True:\n        query = input(\"Enter a query sentence (or type 'exit' to quit): \")\n        if query.lower() == 'exit':\n            break\n        top_paragraphs = semantic_search(query, corpus_embeddings)\n        \n        print(\"\\nTop 5 paragraphs:\")\n        for i, para in enumerate(top_paragraphs, 1):\n            print(f\"{i}: {para}\")\n\n        question = query\n        answers = answer_question(question, top_paragraphs[0])\n        \n        print(\"\\nAnswers based on top paragraphs:\")\n        for paragraph, answer, score in answers:\n            print(f\"Answer: {answer}\\nScore: {score:.4f}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:26:21.396502Z","iopub.execute_input":"2024-05-23T15:26:21.397164Z","iopub.status.idle":"2024-05-23T15:28:33.374671Z","shell.execute_reply.started":"2024-05-23T15:26:21.397127Z","shell.execute_reply":"2024-05-23T15:28:33.373628Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  Who sent her a letter asking that she reconsider the Pepsi deal?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0286b42420e34830ab817182a1de7762"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: Pepsi revoked the commercial and canceled her sponsorship contract.\n2: Pepsi revoked the commercial and canceled her sponsorship contract.\n3: Pepsi revoked the commercial and canceled her sponsorship contract.\n4: Pepsi revoked the commercial and canceled her sponsorship contract.\n5: In 2012, Beyoncé signed a $50 million deal to endorse Pepsi.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: Pepsi\nScore: 0.6519\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  Who was the AFL's 2013 national broadcast partner?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a83a2b3872cd44f18c8f7c2fb23016aa"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: Starting in 2014, ESPN returned to the AFL as broadcast partners, with weekly games being shown on CBS Sports Network, ESPN, ESPN2, ESPNEWS along with all games being broadcast on ESPN3 for free live on WatchESPN.\n2: Starting in 2014, ESPN returned to the AFL as broadcast partners, with weekly games being shown on CBS Sports Network, ESPN, ESPN2, ESPNEWS along with all games being broadcast on ESPN3 for free live on WatchESPN.\n3: Starting in 2014, ESPN returned to the AFL as broadcast partners, with weekly games being shown on CBS Sports Network, ESPN, ESPN2, ESPNEWS along with all games being broadcast on ESPN3 for free live on WatchESPN.\n4: For the 2013 season, the league's new national broadcast partner was the CBS Sports Network.\n5: For the 2013 season, the league's new national broadcast partner was the CBS Sports Network.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: ESPN\nScore: 0.8988\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  What is the  parts of the trophy?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8717304d03453ba5757abf1602ac46"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: The trophy comes in three parts - the cup itself, plus a lid and a base.\n2: The trophy comes in three parts - the cup itself, plus a lid and a base.\n3: The trophy comes in three parts - the cup itself, plus a lid and a base.\n4: The trophy comes in three parts - the cup itself, plus a lid and a base.\n5: The trophy comes in three parts - the cup itself, plus a lid and a base.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: the cup itself, plus a lid and a base\nScore: 0.7866\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  Is there any structural damage associated with secretory diarrhea?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1f965aa7e143b58af3415bb7ae460f"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption.\n2: Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption.\n3: Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption.\n4: Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption.\n5: Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: there is an inhibition of absorption\nScore: 0.0553\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  quit\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d942d6071304d158d00f8c1c0fa921d"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 paragraphs:\n1: Blair announced in September 2006 that he would quit as leader within the year, though he had been under pressure to quit earlier than May 2007 in order to get a new leader in place before the May elections which were expected to be disastrous for Labour.\n2: Blair announced in September 2006 that he would quit as leader within the year, though he had been under pressure to quit earlier than May 2007 in order to get a new leader in place before the May elections which were expected to be disastrous for Labour.\n3: Blair announced in September 2006 that he would quit as leader within the year, though he had been under pressure to quit earlier than May 2007 in order to get a new leader in place before the May elections which were expected to be disastrous for Labour.\n4: Blair announced in September 2006 that he would quit as leader within the year, though he had been under pressure to quit earlier than May 2007 in order to get a new leader in place before the May elections which were expected to be disastrous for Labour.\n5: Blair announced in September 2006 that he would quit as leader within the year, though he had been under pressure to quit earlier than May 2007 in order to get a new leader in place before the May elections which were expected to be disastrous for Labour.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"\nAnswers based on top paragraphs:\nAnswer: Blair announced in September 2006 that he would quit as leader within the year\nScore: 0.1347\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter a query sentence (or type 'exit' to quit):  exit\n"}]},{"cell_type":"markdown","source":"# Tried gradio throwing error on kaggle","metadata":{}},{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:28:38.201292Z","iopub.execute_input":"2024-05-23T15:28:38.202245Z","iopub.status.idle":"2024-05-23T15:28:58.336115Z","shell.execute_reply.started":"2024-05-23T15:28:38.202207Z","shell.execute_reply":"2024-05-23T15:28:58.334870Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-4.31.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.108.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.16.4 (from gradio)\n  Downloading gradio_client-0.16.4-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.2)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.4)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.9 (from gradio)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.1)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting typer<1.0,>=0.12 (from gradio)\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.9.0)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.16.4->gradio) (2024.2.0)\nCollecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.32.0.post1)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=bb4305c4c8eeba1cdfd80db373d25e867034196aad1c615d2ffa599a973c5e53\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, websockets, urllib3, tomlkit, semantic-version, ruff, python-multipart, typer, gradio-client, gradio\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.12.4\n    Uninstalling tomlkit-0.12.4:\n      Successfully uninstalled tomlkit-0.12.4\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpy-0.3.2 gradio-4.31.5 gradio-client-0.16.4 python-multipart-0.0.9 ruff-0.4.5 semantic-version-2.10.0 tomlkit-0.12.0 typer-0.12.3 urllib3-2.1.0 websockets-11.0.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Did implementation on gradio","metadata":{}},{"cell_type":"code","source":"import gradio as gr\ndef process_query(query):\n    if query.lower() == 'exit':\n        return [], []\n\n    # Perform semantic search\n    top_paragraphs = semantic_search(query, corpus_embeddings)\n    \n    # Answer the question based on the top paragraph\n    question = query\n    answers = answer_question(question, top_paragraphs[0])\n    \n    return top_paragraphs, answers\n\ndef gradio_interface(query):\n    top_paragraphs, answers = process_query(query)\n    \n    # Format the output\n    paragraphs_output = \"\\n\".join([f\"{i+1}: {para}\" for i, para in enumerate(top_paragraphs)])\n    answers_output = \"\\n\\n\".join([f\"Answer: {answer}\\nScore: {score:.4f}\" for _, answer, score in answers])\n    \n    return paragraphs_output, answers_output\n\n# Create the Gradio interface\niface = gr.Interface(\n    fn=gradio_interface,\n    inputs=\"text\",\n    outputs=[\"text\", \"text\"],\n    title=\"Semantic Search and Question Answering\",\n    description=\"Enter a query to get the top 5 paragraphs and answers based on the top paragraph.\"\n)\n\n# Launch the Gradio interface\niface.launch(share=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:29:01.237495Z","iopub.execute_input":"2024-05-23T15:29:01.237902Z","iopub.status.idle":"2024-05-23T15:29:09.240721Z","shell.execute_reply.started":"2024-05-23T15:29:01.237866Z","shell.execute_reply":"2024-05-23T15:29:09.239848Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://a73a15813e923ff5e6.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://a73a15813e923ff5e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c2c3d1578747899e5e9f83fe1d3938"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}